{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **k-Nearest Neighbor (k-NN) Algorithm**\n",
    "\n",
    "---\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "The k-Nearest Neighbor (k-NN) algorithm is a **non-parametric**, **lazy learning** algorithm widely used for classification and regression tasks. It operates based on the idea of similarity: the label or value of a data point is determined by the majority label or average of its nearest neighbors.\n",
    "\n",
    "---\n",
    "\n",
    "## **How k-NN Works**\n",
    "\n",
    "### **Algorithm Steps**\n",
    "\n",
    "1. **Choose the value of \\( k \\):**\n",
    "\n",
    "   - \\( k \\) represents the number of nearest neighbors to consider.\n",
    "\n",
    "2. **Calculate Distance:**\n",
    "\n",
    "   - Compute the distance between the test point and all training points using a distance metric such as:\n",
    "     - **Euclidean Distance**:  \n",
    "       $$ d = \\sqrt{\\sum\\_{i=1}^{n} (x_i - y_i)^2} $$\n",
    "     - **Manhattan Distance**:  \n",
    "       $$ d = \\sum\\_{i=1}^{n} |x_i - y_i| $$\n",
    "\n",
    "3. **Identify Nearest Neighbors:**\n",
    "\n",
    "   - Sort the training points based on the distance to the test point.\n",
    "   - Select the \\( k \\) closest points.\n",
    "\n",
    "4. **Assign a Label (Classification):**\n",
    "\n",
    "   - For classification tasks, assign the test point the label that appears most frequently among the \\( k \\) neighbors.\n",
    "\n",
    "5. **Predict a Value (Regression):**\n",
    "\n",
    "   - For regression tasks, take the average value of the \\( k \\) neighbors.\n",
    "\n",
    "6. **Evaluate Accuracy:**\n",
    "   - Compare the predictions with the true labels to evaluate the model's performance.\n",
    "\n",
    "---\n",
    "\n",
    "## **Advantages of k-NN**\n",
    "\n",
    "1. **Simplicity:**\n",
    "\n",
    "   - Easy to understand and implement, requiring no assumptions about the underlying data distribution.\n",
    "\n",
    "2. **Flexibility:**\n",
    "\n",
    "   - Can be used for both classification and regression tasks.\n",
    "\n",
    "3. **Non-Parametric:**\n",
    "\n",
    "   - k-NN makes no assumptions about the data, making it effective for a wide range of problems.\n",
    "\n",
    "4. **Adaptability:**\n",
    "   - Adapts to data complexity as the decision boundary depends on the proximity of points.\n",
    "\n",
    "---\n",
    "\n",
    "## **Disadvantages of k-NN**\n",
    "\n",
    "1. **Computational Complexity:**\n",
    "\n",
    "   - k-NN requires computing the distance to all training points for each test point, which can be slow for large datasets.\n",
    "\n",
    "2. **Memory Usage:**\n",
    "\n",
    "   - Since the algorithm stores all training data, it can be memory-intensive.\n",
    "\n",
    "3. **Sensitivity to Features:**\n",
    "\n",
    "   - k-NN is sensitive to irrelevant or scaled features. Feature normalization or standardization is often required.\n",
    "\n",
    "4. **Curse of Dimensionality:**\n",
    "\n",
    "   - Performance degrades as the number of dimensions increases due to sparse data in high-dimensional spaces.\n",
    "\n",
    "5. **Imbalanced Data:**\n",
    "   - The algorithm may perform poorly when class distributions are imbalanced, as it relies on majority voting.\n",
    "\n",
    "---\n",
    "\n",
    "## **Applications of k-NN**\n",
    "\n",
    "1. **Pattern Recognition:**\n",
    "\n",
    "   - Used for image classification, facial recognition, and handwriting recognition.\n",
    "\n",
    "2. **Recommendation Systems:**\n",
    "\n",
    "   - Suggests products or services based on user similarity.\n",
    "\n",
    "3. **Healthcare:**\n",
    "\n",
    "   - Diagnosis of diseases using patient data.\n",
    "\n",
    "4. **Anomaly Detection:**\n",
    "   - Identifies unusual patterns in datasets, such as fraud detection.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "The k-Nearest Neighbor algorithm is a versatile and intuitive method for solving classification and regression problems. While it has its limitations, it can be highly effective when used with appropriately preprocessed data and careful tuning of the hyperparameter \\( k \\).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy with Distorted Data</td>\n",
       "      <td>93.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Metric       Value\n",
       "0                      Accuracy  100.000000\n",
       "1  Accuracy with Distorted Data   93.333333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Original Data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "0                   1.0     1.0       1.0     10.0\n",
       "1                   1.0     1.0       1.0      9.0\n",
       "2                   1.0     1.0       1.0     11.0\n",
       "accuracy            1.0     1.0       1.0      1.0\n",
       "macro avg           1.0     1.0       1.0     30.0\n",
       "weighted avg        1.0     1.0       1.0     30.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Distorted Data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.943590</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.931944</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score    support\n",
       "0              1.000000  1.000000  1.000000  10.000000\n",
       "1              1.000000  0.777778  0.875000   9.000000\n",
       "2              0.846154  1.000000  0.916667  11.000000\n",
       "accuracy       0.933333  0.933333  0.933333   0.933333\n",
       "macro avg      0.948718  0.925926  0.930556  30.000000\n",
       "weighted avg   0.943590  0.933333  0.931944  30.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd  # For handling dataframes\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Labels\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the k-NN classifier\n",
    "k = 3  # Number of neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on original test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model on original test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_original = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Analyze performance with distortions\n",
    "X_test_distorted = X_test + np.random.normal(0, 0.5, X_test.shape)  # Adding noise to the test data\n",
    "y_pred_distorted = knn.predict(X_test_distorted)\n",
    "accuracy_distorted = accuracy_score(y_test, y_pred_distorted)\n",
    "classification_report_distorted = classification_report(y_test, y_pred_distorted, output_dict=True)\n",
    "\n",
    "# Store results in a DataFrame\n",
    "results = {\n",
    "    \"Metric\": [\"Accuracy\", \"Accuracy with Distorted Data\"],\n",
    "    \"Value\": [accuracy * 100, accuracy_distorted * 100],\n",
    "}\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Save detailed classification reports in DataFrames\n",
    "df_classification_original = pd.DataFrame(classification_report_original).transpose()\n",
    "df_classification_distorted = pd.DataFrame(classification_report_distorted).transpose()\n",
    "\n",
    "# Save outputs to CSV files\n",
    "# df_results.to_csv(\"knn_results.csv\", index=False)\n",
    "# df_classification_original.to_csv(\"classification_report_original.csv\", index=True)\n",
    "# df_classification_distorted.to_csv(\"classification_report_distorted.csv\", index=True)\n",
    "\n",
    "# Print outputs\n",
    "print(\"Overall Results:\")\n",
    "display(df_results)\n",
    "\n",
    "print(\"\\nClassification Report (Original Data):\")\n",
    "display(df_classification_original)\n",
    "\n",
    "print(\"\\nClassification Report (Distorted Data):\")\n",
    "display(df_classification_distorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **k-Nearest Neighbor (k-NN) with Visualization**\n",
    "\n",
    "This notebook demonstrates the implementation of the k-Nearest Neighbor (k-NN) algorithm and visualizes its decision boundaries. The dataset consists of 2D points classified into two classes.\n",
    "\n",
    "---\n",
    "\n",
    "## **Code Explanation**\n",
    "\n",
    "1. **Initialization of the k-NN Classifier**\n",
    "\n",
    "   - The `KNearestNeighbor` class implements the k-NN algorithm.\n",
    "   - It requires:\n",
    "     - `k`: Number of neighbors to consider.\n",
    "     - Training data: `X_train` (features) and `y_train` (labels).\n",
    "\n",
    "2. **Training (`fit` method)**\n",
    "\n",
    "   - The `fit` method stores the training data for comparison during prediction.\n",
    "\n",
    "3. **Prediction (`predict` method)**\n",
    "\n",
    "   - For each test point:\n",
    "     - Compute distances to all training points.\n",
    "     - Identify the `k` nearest neighbors.\n",
    "     - Assign the label based on the majority class among the neighbors.\n",
    "\n",
    "4. **Visualization**\n",
    "   - A grid of points is created to visualize decision boundaries.\n",
    "   - Each grid point is classified using the k-NN classifier.\n",
    "   - The decision boundary is visualized as regions of different colors, separated by class.\n",
    "   - The training points and test points are plotted, with test points marked as stars (`*`).\n",
    "\n",
    "---\n",
    "\n",
    "## **Outputs**\n",
    "\n",
    "1. **Predicted Labels:**\n",
    "\n",
    "   - Displays the predicted labels for test points.\n",
    "\n",
    "2. **Decision Boundary Plot:**\n",
    "   - Visualizes the classification regions and the placement of test points relative to the training data.\n",
    "\n",
    "---\n",
    "\n",
    "## **Observations**\n",
    "\n",
    "- The decision boundary adapts to the local structure of the data.\n",
    "- Test points are classified based on proximity to training points.\n",
    "- The number of neighbors (`k`) can significantly influence the boundary shape and model behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Model  Original Accuracy  Distorted Accuracy\n",
      "0   Custom k-NN               0.98                0.94\n",
      "1  Sklearn k-NN               0.98                0.94\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Custom K Nearest Neighbors Classifier\n",
    "class K_Nearest_Neighbors_Classifier:\n",
    "    def __init__(self, K):\n",
    "        self.K = K\n",
    "    \n",
    "    # Function to store training set\n",
    "    def fit(self, X_train, Y_train):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.m, self.n = X_train.shape\n",
    "\n",
    "    # Function for prediction\n",
    "    def predict(self, X_test):\n",
    "        self.X_test = X_test\n",
    "        self.m_test, self.n = X_test.shape\n",
    "        Y_predict = np.zeros(self.m_test)\n",
    "\n",
    "        for i in range(self.m_test):\n",
    "            x = self.X_test[i]\n",
    "            neighbors = self.find_neighbors(x)\n",
    "            mode_value = self.safe_mode(neighbors)  # Safely access mode value\n",
    "            Y_predict[i] = mode_value\n",
    "        \n",
    "        return Y_predict\n",
    "    \n",
    "    # Function to find the K nearest neighbors to current test example\n",
    "    def find_neighbors(self, x):\n",
    "        euclidean_distances = np.zeros(self.m)\n",
    "        \n",
    "        for i in range(self.m):\n",
    "            d = self.euclidean(x, self.X_train[i])\n",
    "            euclidean_distances[i] = d\n",
    "        \n",
    "        inds = euclidean_distances.argsort()\n",
    "        Y_train_sorted = self.Y_train[inds]\n",
    "        \n",
    "        return Y_train_sorted[:self.K]\n",
    "    \n",
    "    # Function to calculate euclidean distance\n",
    "    def euclidean(self, x, x_train):\n",
    "        return np.sqrt(np.sum(np.square(x - x_train)))\n",
    "    \n",
    "    # Function to safely extract mode value\n",
    "    def safe_mode(self, neighbors):\n",
    "        mode_result = mode(neighbors)\n",
    "        if isinstance(mode_result[0], np.ndarray):  # If multiple modes exist\n",
    "            return mode_result[0][0]\n",
    "        else:  # If only one mode exists\n",
    "            return mode_result[0]\n",
    "\n",
    "# Driver code\n",
    "def main():\n",
    "    # Load the Iris dataset\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    \n",
    "    # Standardize the dataset for better performance\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split the dataset into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=42)\n",
    "    \n",
    "    # Initialize and train the custom K-NN model\n",
    "    model = K_Nearest_Neighbors_Classifier(K=3)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the sklearn K-NN model\n",
    "    model1 = KNeighborsClassifier(n_neighbors=3)\n",
    "    model1.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the original test set\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_pred1 = model1.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy for original data\n",
    "    accuracy_custom_original = accuracy_score(y_test, Y_pred)\n",
    "    accuracy_sklearn_original = accuracy_score(y_test, Y_pred1)\n",
    "    \n",
    "    # Add distortion (noise) to the test data\n",
    "    np.random.seed(42)\n",
    "    noise = np.random.normal(0, 0.5, X_test.shape)\n",
    "    X_test_distorted = X_test + noise\n",
    "    \n",
    "    # Predict on the distorted test set\n",
    "    Y_pred_distorted = model.predict(X_test_distorted)\n",
    "    Y_pred1_distorted = model1.predict(X_test_distorted)\n",
    "    \n",
    "    # Calculate accuracy for distorted data\n",
    "    accuracy_custom_distorted = accuracy_score(y_test, Y_pred_distorted)\n",
    "    accuracy_sklearn_distorted = accuracy_score(y_test, Y_pred1_distorted)\n",
    "    \n",
    "    # Create a DataFrame for comparison\n",
    "    results = pd.DataFrame({\n",
    "        \"Model\": [\"Custom k-NN\", \"Sklearn k-NN\"],\n",
    "        \"Original Accuracy\": [accuracy_custom_original, accuracy_sklearn_original],\n",
    "        \"Distorted Accuracy\": [accuracy_custom_distorted, accuracy_sklearn_distorted]\n",
    "    })\n",
    "    \n",
    "    # Display the results\n",
    "    print(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
