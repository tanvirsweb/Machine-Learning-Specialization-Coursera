{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.11.5' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARD_SIZE = 3\n",
    "WINNING_COMBOS = [\n",
    "    [0, 1, 2], [3, 4, 5], [6, 7, 8],  # Rows\n",
    "    [0, 3, 6], [1, 4, 7], [2, 5, 8],  # Columns\n",
    "    [0, 4, 8], [2, 4, 6]              # Diagonals\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_board(board):\n",
    "    for i in range(0, 9, BOARD_SIZE):\n",
    "        print(' '.join(['X' if board[i+j] == 1 else 'O' if board[i+j] == -1 else '.' for j in range(BOARD_SIZE)]))\n",
    "        \n",
    "\n",
    "def is_winner(board, player):\n",
    "    for combo in WINNING_COMBOS:\n",
    "        if all(board[i] == player for i in combo):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_full(board):\n",
    "    return all(cell != 0 for cell in board)\n",
    "\n",
    "def get_empty_positions(board):\n",
    "    return [i for i in range(len(board)) if board[i] == 0]\n",
    "\n",
    "def make_move(board, position, player):\n",
    "    board[position] = player\n",
    "\n",
    "def get_opponent(player):\n",
    "    return -player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToeAgent:\n",
    "    def __init__(self, player):\n",
    "        self.player = player\n",
    "        self.q_table = {}\n",
    "        self.learning_rate = 0.1\n",
    "        self.discount_factor = 0.9\n",
    "        self.exploration_rate = 0.2\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        return self.q_table.get((tuple(state), action), 0)\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state, next_action):\n",
    "        max_future_q = max(self.get_q_value(next_state, a) for a in get_empty_positions(next_state))\n",
    "        current_q = self.get_q_value(state, action)\n",
    "        new_q = current_q + self.learning_rate * (reward + self.discount_factor * max_future_q - current_q)\n",
    "        self.q_table[(tuple(state), action)] = new_q\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        empty_positions = get_empty_positions(state)\n",
    "        if random.random() < self.exploration_rate:\n",
    "            return random.choice(empty_positions)\n",
    "        q_values = [(self.get_q_value(state, pos), pos) for pos in empty_positions]\n",
    "        return max(q_values)[1]\n",
    "\n",
    "    def train(self, games=1000):\n",
    "        for _ in range(games):\n",
    "            state = [0] * 9\n",
    "            current_player = 1\n",
    "            while not is_full(state) and not is_winner(state, 1) and not is_winner(state, -1):\n",
    "                action = self.choose_action(state)\n",
    "                make_move(state, action, current_player)\n",
    "                if is_winner(state, current_player):\n",
    "                    reward = 1 if current_player == self.player else -1\n",
    "                else:\n",
    "                    reward = 0\n",
    "                next_state = state.copy()\n",
    "                next_action = self.choose_action(next_state)\n",
    "                self.update_q_value(state, action, reward, next_state, next_action)\n",
    "                state = next_state\n",
    "                current_player = get_opponent(current_player)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(agent_x, agent_o):\n",
    "    board = [0] * 9\n",
    "    current_player = 1  # X starts first\n",
    "    while not is_full(board) and not is_winner(board, 1) and not is_winner(board, -1):\n",
    "        if current_player == 1:\n",
    "            action = agent_x.choose_action(board)\n",
    "        else:\n",
    "            action = agent_o.choose_action(board)\n",
    "        make_move(board, action, current_player)\n",
    "        current_player = get_opponent(current_player)\n",
    "    \n",
    "    print_board(board)\n",
    "    if is_winner(board, 1):\n",
    "        return 1\n",
    "    elif is_winner(board, -1):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Training the agent\n",
    "agent_x = TicTacToeAgent(1)\n",
    "agent_o = TicTacToeAgent(-1)\n",
    "agent_x.train(games=1000)\n",
    "\n",
    "# Test the trained agent by playing a game\n",
    "result = play_game(agent_x, agent_o)\n",
    "print(f\"Game result: {'X wins' if result == 1 else 'O wins' if result == -1 else 'Draw'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
